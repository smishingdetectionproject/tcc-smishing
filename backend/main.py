"""
Detector de Smishing - Backend API
Projeto de TCC da UNIVESP

Este arquivo cont√©m a API FastAPI que realiza a an√°lise de mensagens SMS
para detectar potenciais tentativas de smishing (phishing por SMS).

Autor: Desenvolvido para o TCC da UNIVESP
Data: 2025
"""

import os
import csv
import json
import requests
from datetime import datetime
from pathlib import Path
from typing import Optional
from io import BytesIO, StringIO
import base64 
import subprocess # Para executar o train.py na rota /train_model

import numpy as np
import pandas as pd
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import joblib
from sklearn.feature_extraction.text import TfidfVectorizer

# ============================================================================
# CONFIGURA√á√ÉO INICIAL
# ============================================================================

# Criar aplica√ß√£o FastAPI
app = FastAPI(
    title="Detector de Smishing",
    description="API para detec√ß√£o de mensagens SMS fraudulentas (smishing)",
    version="1.0.0"
)

# Configurar CORS para permitir requisi√ß√µes do frontend
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Em produ√ß√£o, especificar dom√≠nios permitidos
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ============================================================================
# CONFIGURA√á√ïES DO GIST
# ============================================================================

# Diret√≥rio do backend
BACKEND_DIR = Path(__file__).parent
MODEL_DIR = BACKEND_DIR / "models"
DATA_DIR = BACKEND_DIR / "data"

# Criar diret√≥rios se n√£o existirem
MODEL_DIR.mkdir(exist_ok=True)
DATA_DIR.mkdir(exist_ok=True)

# Vari√°veis de ambiente para o Gist
GIST_MODEL_ID = os.environ.get("GIST_MODEL_ID")
GIST_FEEDBACK_ID = os.environ.get("GIST_FEEDBACK_ID")
GITHUB_PAT = os.environ.get("GITHUB_PAT")

# Vari√°veis globais para os modelos
tfidf_vectorizer = None
model_rf = None
model_nb = None
f1_score_rf = 0.0
f1_score_nb = 0.0

# ============================================================================
# FUN√á√ïES DE COMUNICA√á√ÉO COM O GIST
# ============================================================================

def get_gist_content(gist_id: str, filename: str) -> Optional[bytes]:
    """Busca o conte√∫do de um arquivo em um Gist."""
    try:
        headers = {}
        if GITHUB_PAT:
            headers["Authorization"] = f"token {GITHUB_PAT}"
            
        response = requests.get(f"https://api.github.com/gists/{gist_id}", headers=headers)
        response.raise_for_status()
        
        gist_data = response.json()
        
        if filename in gist_data['files']:
            raw_url = gist_data['files'][filename]['raw_url']
            content_response = requests.get(raw_url)
            content_response.raise_for_status()
            return content_response.content
        
        return None
    except requests.exceptions.RequestException as e:
        print(f"‚úó Erro ao buscar Gist {gist_id}: {e}")
        return None

def load_models_from_gist():
    """Carrega o vetorizador e os modelos ativos do Gist."""
    global tfidf_vectorizer, model_rf, model_nb, f1_score_rf, f1_score_nb
    
    if not GIST_MODEL_ID:
        print("‚úó Vari√°vel GIST_MODEL_ID n√£o configurada. Usando modelos locais (Fallback).")
        return load_local_models()

    try:
        # 1. Carregar o bin√°rio do modelo
        model_binary = get_gist_content(GIST_MODEL_ID, "model.joblib")
        
        if not model_binary:
            print("‚úó Arquivo model.joblib n√£o encontrado no Gist. Usando modelos locais (Fallback).")
            return load_local_models()
            
        # 2. Carregar o bin√°rio do F1-Score
        metrics_content = get_gist_content(GIST_MODEL_ID, "metrics.json")
        
        if not metrics_content:
            print("‚úó Arquivo metrics.json n√£o encontrado no Gist. Usando modelos locais (Fallback).")
            return load_local_models()
            
        metrics = json.loads(metrics_content.decode('utf-8'))
        f1_score_rf = metrics.get("random_forest", {}).get("f1_score", 0.0)
        f1_score_nb = metrics.get("naive_bayes", {}).get("f1_score", 0.0)
        
        # 3. Desempacotar o modelo
        pipeline = joblib.load(BytesIO(model_binary))
        
        tfidf_vectorizer = pipeline['vectorizer']
        model_rf = pipeline['model_rf']
        model_nb = pipeline['model_nb']
        
        print(f"‚úì Modelos carregados do Gist com sucesso.")
        print(f"  - Random Forest F1-Score: {f1_score_rf:.4f}")
        print(f"  - Naive Bayes F1-Score: {f1_score_nb:.4f}")
        
    except Exception as e:
        print(f"‚úó Erro ao carregar modelos do Gist: {e}. Usando modelos locais (Fallback).")
        load_local_models()

def load_local_models():
    """Carrega modelos locais (Fallback)."""
    global tfidf_vectorizer, model_rf, model_nb
    try:
        import pickle
        with open(BACKEND_DIR / "tfidf_vectorizer.pkl", "rb") as f:
            tfidf_vectorizer = pickle.load(f)
        with open(BACKEND_DIR / "random_forest.pkl", "rb") as f:
            model_rf = pickle.load(f)
        with open(BACKEND_DIR / "complement_naive_bayes.pkl", "rb") as f:
            model_nb = pickle.load(f)
        print("‚úì Modelos locais carregados com sucesso (Fallback).")
    except Exception as e_local:
        print(f"‚úó Erro ao carregar modelos locais: {e_local}")

def save_feedback_to_gist(feedback_data: dict):
    """Salva o feedback em um Gist (append)."""
    if not GIST_FEEDBACK_ID:
        print("‚úó Vari√°vel GIST_FEEDBACK_ID n√£o configurada. Feedback n√£o salvo.")
        return

    try:
        # 1. Obter o conte√∫do atual do feedback.csv
        current_content = get_gist_content(GIST_FEEDBACK_ID, "feedback.csv")
        
        # 2. Preparar o novo feedback
        new_feedback_df = pd.DataFrame([feedback_data])
        new_feedback_csv = new_feedback_df.to_csv(index=False, header=False)
        
        # 3. Se houver conte√∫do, remove o cabe√ßalho do novo feedback
        if current_content:
            current_csv = current_content.decode('utf-8')
            # Verifica se o cabe√ßalho existe no conte√∫do atual
            if not current_csv.strip().startswith("mensagem,veredito_original,feedback_util,comentario_usuario"):
                # Se n√£o houver cabe√ßalho, adiciona
                header = "mensagem,veredito_original,feedback_util,comentario_usuario\n"
                current_csv = header + current_csv
            
            # Adiciona o novo feedback (sem cabe√ßalho)
            updated_content = current_csv.strip() + "\n" + new_feedback_csv.strip()
        else:
            # Se n√£o houver conte√∫do, usa o novo feedback com cabe√ßalho
            updated_content = new_feedback_df.to_csv(index=False, header=True)
            
        # 4. Atualizar o Gist
        headers = {"Authorization": f"token {GITHUB_PAT}"}
        update_data = {
            "files": {
                "feedback.csv": {
                    "content": updated_content
                }
            }
        }
        
        response = requests.patch(f"https://api.github.com/gists/{GIST_FEEDBACK_ID}", headers=headers, json=update_data)
        response.raise_for_status()
        print("‚úì Feedback salvo no Gist com sucesso.")
        
    except requests.exceptions.RequestException as e:
        print(f"‚úó Erro ao salvar feedback no Gist: {e}")

@app.on_event("startup")
def on_startup():
    """Carrega os modelos na inicializa√ß√£o da API."""
    load_models_from_gist()

# ============================================================================
# MODELOS DE DADOS (Pydantic)
# ============================================================================

class AnaliseRequest(BaseModel):
    """Modelo para requisi√ß√£o de an√°lise de SMS"""
    mensagem: str
    modelo: Optional[str] = "random_forest"  # random_forest ou naive_bayes


class CaracteristicaDetectada(BaseModel):
    """Modelo para uma caracter√≠stica detectada na mensagem"""
    nome: str
    descricao: str
    icone: str
    confianca: float


class AnaliseResponse(BaseModel):
    """Modelo para resposta de an√°lise"""
    veredito: str  # "Leg√≠tima" ou "Smishing"
    confianca: float
    caracteristicas: list[CaracteristicaDetectada]
    explicacao: str
    modelo_usado: str


class FeedbackRequest(BaseModel):
    """Modelo para requisi√ß√£o de feedback"""
    mensagem: str
    veredito_original: str
    feedback_util: bool
    comentario_usuario: Optional[str] = None


class FeedbackResponse(BaseModel):
    """Modelo para resposta de feedback"""
    sucesso: bool
    mensagem: str


# ============================================================================
# FUN√á√ïES AUXILIARES
# ============================================================================

def extrair_caracteristicas_smishing(mensagem: str) -> list[CaracteristicaDetectada]:
    """
    Extrai caracter√≠sticas que indicam poss√≠vel smishing.
    (Fun√ß√£o simplificada para demonstra√ß√£o)
    """
    caracteristicas = []
    
    # 1. Links Suspeitos
    if "http" in mensagem.lower() or "www." in mensagem.lower() or "clique aqui" in mensagem.lower():
        caracteristicas.append(CaracteristicaDetectada(
            nome="Link Suspeito",
            descricao="Presen√ßa de URL ou chamada para clique (phishing).",
            icone="üîó",
            confianca=0.8
        ))
        
    # 2. Urg√™ncia e Amea√ßa
    if "urgente" in mensagem.lower() or "bloqueada" in mensagem.lower() or "expira" in mensagem.lower():
        caracteristicas.append(CaracteristicaDetectada(
            nome="Urg√™ncia/Amea√ßa",
            descricao="Uso de palavras que for√ßam a√ß√£o imediata (t√°tica de smishing).",
            icone="üö®",
            confianca=0.7
        ))
        
    # 3. Pedido de Dados Pessoais
    if "cpf" in mensagem.lower() or "senha" in mensagem.lower() or "dados" in mensagem.lower():
        caracteristicas.append(CaracteristicaDetectada(
            nome="Pedido de Dados",
            descricao="Solicita√ß√£o de informa√ß√µes pessoais ou financeiras.",
            icone="üîí",
            confianca=0.9
        ))
        
    # 4. Erros de Portugu√™s (Indicador fraco, mas √∫til)
    # Implementa√ß√£o simplificada: verifica se h√° palavras muito curtas ou com erros √≥bvios
    palavras = mensagem.split()
    erros = sum(1 for p in palavras if len(p) < 3 and p.isalpha())
    if erros > 2:
        caracteristicas.append(CaracteristicaDetectada(
            nome="Erros Gramaticais",
            descricao="Poss√≠veis erros de portugu√™s ou formata√ß√£o estranha.",
            icone="üìù",
            confianca=0.4
        ))
        
    return caracteristicas

def preprocess_text(text):
    """Fun√ß√£o de pr√©-processamento de texto (simplificada)."""
    if pd.isna(text):
        return ""
    text = text.lower()
    # Adicione aqui mais etapas de pr√©-processamento se necess√°rio (remo√ß√£o de stopwords, pontua√ß√£o, etc.)
    return text

# ============================================================================
# ROTAS DA API
# ============================================================================

@app.get("/")
def read_root():
    """Rota de sa√∫de da API."""
    return {
        "status": "online", 
        "modelos_carregados": model_rf is not None and model_nb is not None,
        "random_forest_f1": f1_score_rf,
        "naive_bayes_f1": f1_score_nb
    }

@app.post("/analisar", response_model=AnaliseResponse)
def analisar_sms(request: AnaliseRequest):
    """
    Analisa uma mensagem SMS e retorna o veredito de smishing.
    """
    if tfidf_vectorizer is None or model_rf is None or model_nb is None:
        raise HTTPException(status_code=503, detail="Modelos de Machine Learning n√£o carregados. Tente novamente mais tarde.")

    # 1. Pr√©-processamento
    texto_processado = preprocess_text(request.mensagem)
    
    # 2. Vetoriza√ß√£o
    texto_vetorizado = tfidf_vectorizer.transform([texto_processado])
    
    # 3. Sele√ß√£o e Predi√ß√£o do Modelo
    modelo_usado = request.modelo.lower()
    
    if modelo_usado == "random_forest":
        model = model_rf
        f1_score_modelo = f1_score_rf
    elif modelo_usado == "naive_bayes":
        model = model_nb
        f1_score_modelo = f1_score_nb
    else:
        raise HTTPException(status_code=400, detail="Modelo inv√°lido. Escolha 'random_forest' ou 'naive_bayes'.")

    # Predi√ß√£o
    predicao = model.predict(texto_vetorizado)[0]
    probabilidade = model.predict_proba(texto_vetorizado)[0]
    
    # 4. Interpreta√ß√£o do Resultado
    veredito = "Smishing" if predicao == 1 else "Leg√≠tima"
    confianca = probabilidade[predicao]
    
    # 5. Extra√ß√£o de Caracter√≠sticas
    caracteristicas = extrair_caracteristicas_smishing(request.mensagem)
    
    # 6. Explica√ß√£o (simplificada)
    explicacao = f"A mensagem foi classificada como '{veredito}' com {confianca*100:.2f}% de confian√ßa. O modelo {modelo_usado} (F1-Score: {f1_score_modelo:.4f}) foi utilizado para a predi√ß√£o."
    
    return AnaliseResponse(
        veredito=veredito,
        confianca=confianca,
        caracteristicas=caracteristicas,
        explicacao=explicacao,
        modelo_usado=modelo_usado
    )

@app.post("/feedback", response_model=FeedbackResponse)
def receber_feedback(request: FeedbackRequest):
    """
    Recebe feedback do usu√°rio para aprimorar o modelo.
    """
    # 1. Preparar os dados para salvar
    feedback_data = {
        "mensagem": request.mensagem,
        "veredito_original": request.veredito_original,
        "feedback_util": request.feedback_util,
        "comentario_usuario": request.comentario_usuario
    }
    
    # 2. Salvar no Gist
    save_feedback_to_gist(feedback_data)
    
    return FeedbackResponse(
        sucesso=True,
        mensagem="Feedback recebido com sucesso. Ser√° usado no pr√≥ximo treinamento."
    )

@app.post("/train_model", response_model=dict)
def train_model_route():
    """
    Dispara o treinamento do modelo (usado pelo cronjob).
    """
    try:
        # Executa o script train.py
        result = subprocess.run(["python3", "train.py"], check=True, cwd=BACKEND_DIR, capture_output=True, text=True)
        
        # Recarrega os modelos ap√≥s o treinamento
        load_models_from_gist()
        
        return {
            "sucesso": True,
            "mensagem": "Treinamento conclu√≠do e modelos recarregados com sucesso.",
            "output": result.stdout
        }
    except subprocess.CalledProcessError as e:
        raise HTTPException(status_code=500, detail=f"Erro no treinamento: {e.stderr}")
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erro ao disparar o treinamento: {e}")
